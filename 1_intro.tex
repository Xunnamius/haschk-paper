\section{Introduction} \label{sec:introduction}

In 2010, through compromising legitimate applications available on trusted
vendor websites, nation-state actors launched the Havex malware, targeting
aviation, defense, pharmaceutical, and other companies in Europe and the United
States~\cite{SCA-HAVEX1, SCA-HAVEX2}. In 2012, attackers compromised an official
phpMyAdmin download mirror hosted by reputable software provider SourceForge.
The backdoored version of the popular database frontend was downloaded by
hundreds of users, potentially allowing attackers to gain access to private
customer data~\cite{SCA-PMA1, SCA-PMA2}. In 2016, attackers broke into the Linux
Mint distribution server and replaced a legitimate Mint ISO with one containing
a backdoor, infecting hundreds of machines with the malware~\cite{SCA-MINT1,
SCA-MINT2}. Over a four day period in 2017, users of the popular HandBrake open
source video transcoder on Mac/OSX were made aware that, along with their
expected video software, they may have also downloaded a trojan that was
uploading their sensitive data to a remote server~\cite{SCA-HB1}. HandBrake
developers recommended users perform \emph{checksum verification} to determine
if their install was compromised~\cite{SCA-HB2}.

Downloading resources over the internet comes with considerable risk. This risk
can be divided into three broad concerns: response authentication, communication
confidentiality, and resource integrity. Response authentication allows us to
determine if a response received indeed originates from its purported source
through, for instance, the adoption of a Public Key Infrastructure (PKI)
scheme~\cite{PKI}. Communication confidentiality allows us to keep the data
transacted between two or more parties private through
some form of encryption, such as AES~\cite{AES}. Finally, resource integrity
allows us to verify that the data we are receiving is the data we are expecting
to receive.

When it comes to response authentication and communication confidentiality
concerns on the internet, the state of the art in attack mitigation is Transport
Layer Security (TLS) and its Hyper Text Transfer Protocol (HTTP)/PKI based
implementation, HTTPS~\cite{TLS1.2, TLS1, TLS0, HTTPS, PKI}. Assuming well
behaved certificate authorities and modern browsing software, TLS and related
protocols, when properly deployed, mitigate myriad attacks on authentication and
confidentiality.

However, as a \textit{communication} protocol, TLS only guarantees the integrity
of each \textit{end to end communication} via message authentication code
(MAC)~\cite{TLS1.2}. But protected encrypted communications mean nothing if the
contents of those communications are corrupted before the fact. Hence, the
integrity of resources at the application layer (rather than the transport
layer) is outside of the model addressed by TLS and HTTPS~\cite{TLS1.2, HTTPS}.

Attacks on resource integrity can be considered a subset of \emph{Supply Chain
Attacks} (SCA). Rather than attack an entity directly, SCAs are the compromise
of an entity's software source code (or any product) via cyber attack, insider
threat, upstream asset compromise, trusted hardware/vendor compromise, or other
attack on one or more phases of the software development life
cycle~\cite{NIST-SCA}. These attacks are hard to detect, even harder to prevent,
and have the goal of infecting and exploiting targets and victims by abusing the
trust between consumer and reputable software vendor~\cite{SCA}.

Ensuring the integrity of resources exchanged over the internet despite SCAs and
other active attacks is a hard and well studied problem~\cite{MD5Header,
HTTP1.1, HTTPS, SRI, LF, OpenPGP1, DNSSEC, PKI, Cherubini, Stickler}. For a long
time, the de facto standard for addressing this risk in the generic case is with
the use of \textit{checksums} coupled with some secure transport medium like
TLS/HTTPS. Checksums in this context are cryptographic digests generated by a
cryptographic hashing function~\cite{Rogaway} run over the resource's file
contents. When a user downloads a file from some source, they are expected to
run the same cryptographic hashing function over their version of the resource
to yield a local checksum and then match it with a checksum given to them by
some trusted authority.

However, checksums come up short as a solution to the resource integrity
problem. Foremost is a well-understood but harsh reality:
\emph{user-apathy}---most users will not be inconvenienced with manually
calculating checksums for the resources they download~\cite{Cherubini, Fagan};
moreover, most users will not take the time to understand what checksums and
integrity verification are~\cite{Cherubini, Tan, Hsiao}. While detailing how
they gained unauthorized access to the servers, one of the hackers behind the
2016 breach of Linux Mint's distribution system went so far as to comment (in
respect to checksums): ``Who the [expletive] checks those
anyway?''~\cite{SCA-MINT3}. Hardly unique to checksum calculation, designers of
security schemes from HTTPS to PGP have found user apathy a difficult problem
space to navigate~\cite{PGPBad, Cherubini}. When it comes to user apathy versus
security warnings (\eg{malicious download alerts, warnings about compromised
websites, expired certificate notifications}), application developers and user
interface (UI) designers face similar difficulties~\cite{Clickthrough, Egelman1,
Egelman2, Jenkins, Modic, Reeder, Silic, Sunshine, Bianchi, Akhawe}.

Even if a user felt the urge to manually calculate and verify a resource's
checksum, they must search for a corresponding ``authoritative checksum'' to
compare against. As there is no standard storage or retrieval methods for
checksums, they could be stored anywhere, or even in multiple different
locations that must then be kept consistent~\cite{Cherubini}; users are not
guaranteed to find an authoritative checksum, even if they are published online
somewhere, even if they appear on the same page as the resource they are trying
to protect. If users do manage to find the authoritative checksum manually and
also recognize the checksums are different, the user is then expected to ``do
the right thing,'' whatever that happens to be in context.

A major part of the problem is the futility of \emph{co-hosting} a resource and
its authoritative checksum on the same distribution system. While cost-effective
compared to hosting two or more discrete systems---one for the resource and one
for the resource's checksum---an attacker that compromises a single distribution
system hosting a resource and its checksum can mutate both, rendering the
checksum irrelevant~\cite{Stickler}. This is true for automated checksum
verification solutions as well~\cite{Cherubini}. The co-hosting problem was
demonstrated by the 2016 hack of Linux Mint's distribution
server~\cite{SCA-MINT1, SCA-MINT2}.

Though they propose a standardized method of making checksums available through
an extension to the World Wide Web Consortium (W3C) subresource integrity (SRI)
specification, the automated integrity verification approach developed by
Cherubini et al. similarly fails to overcome co-hosting and remaining structural
problems described above~\cite{Cherubini}.

Hence, checksums as they are typically deployed are not very effective at
guaranteeing resource integrity, even if automatic verification by web clients
is attempted. Recognizing this, some corporations and large entities rely
instead on PKI-based approaches such as digital signature validation and code
signing~\cite{PKI}. These roll-your-own solutions, often proprietary, have been
deployed successfully to mitigate resource integrity attacks in mature software
package ecosystems (\eg Debian/apt, Red Hat/yum, Arch/pacman) and walled-garden
app stores like Google Play, Apple App Store, and the Microsoft Store.

Unfortunately, not all resources available on the internet are acquired through
mature software package ecosystems with built-in PKI support, nor are all
resources software binaries. In the United States for instance, most internet
users download software directly from developers' websites or other
locations~\cite{Cherubini, File}. Moreover, such PKI schemes are not compatible
with one another and cannot scale to secure arbitrary resources on the internet
without significant cost and implementation/deployment effort.

In this paper, we propose \SYSTEM{}, a novel approach for verifying the
integrity of resources downloaded over the internet that is a complete
replacement for traditional checksum-based schemes.

We view the problem with four key concerns in mind. 1) \SYSTEM{} implementations
must provide security guarantees transparently without adding any extra burden
on the end user in the average case. Here, an optimal implementation avoids
relying on the user to overcome \textbf{user apathy} in the interest of security
while accounting for users' tendency to click through security warnings. 2) When
a developer makes a resource available for download on the internet, \SYSTEM{}
protections must be low effort to integrate and deploy, performant, and avoid
the need to configure an expensive dedicated secondary system to host checksums
(\ie \textbf{co-hosting}). 3) The verification method is not tightly coupled
with any particular highly available system. 4) No application or website source
code changes or user-facing server or web infrastructure modifications are
necessary.

We implement \SYSTEM{} as two discrete proof-of-concept Google Chrome
extensions: one relying on DNS as a highly available backend and the other
piggybacking off an OpenDHT-based highly available Ring backend.

We then evaluate the security, deployability, scalability, and performance of
our automated defense against resource corruption and demonstrate the
effectiveness and practicality of the \SYSTEM{} approach. Specifically, we find
no additional obstacles to efficient deployment at scale outside of those
imposed by the chosen high availability system.

For our implementations, we provide a publicly accessible empirical
demonstration of \SYSTEM{}'s utility via a patched HotCRP instance. During our
evaluation, given the obviously lightweight cryptographic operations employed,
we observe no download performance overhead compared to downloads without
\SYSTEM{}. We also release our \DNSSYS{} and \DHTSYS{} implementations to the
community as open source software to promote exploration of the \SYSTEM{}
approach (cf. \secref{availability}).

In summary, our primary contributions are:

\begin{itemize}

  \item We propose a practical approach to automatically and transparently
  mitigating the accidental consumption of compromised resources over the
  internet. Contrasted with current solutions, our concrete implementations
  require no app/website source, end user facing server or web infrastructure
  modifications, do not employ unreliable heuristics, do not expect checksums to
  be co-hosted on the same page as do other automated solutions, and can be
  transparently deployed without adding to application/infrastructure fragility;
  \eg \SYSTEM{}-aware clients will have their downloads secured while the user
  experience of clients unaware of \SYSTEM{} remain completely unaffected.
  Further, our approach can be applied to more than just browsers. \SYSTEM{} can
  be implemented to protect downloads in FTP clients, BitTorrent clients, SSH
  (like rsync), etc.

  \item We present our prototype \SYSTEM{} implementations: \DNSSYS{} and
  \DHTSYS{}. Both are implemented as Google Chrome extensions. We demonstrate
  our implementations' effectiveness in automatically mitigating compromised
  resource consumption using dummy test servers. To the best of our knowledge,
  this is the first approach that 1) is not susceptible to the pitfalls of
  co-hosting or the lack of standard practices for making authoritative
  checksums available to end users, unlike a manual verification approach or
  other automated solutions and 2) provides such capabilities with marginal
  deployment overhead for developers.

  \item We extensively evaluate the security, performance, and deployment
  overhead of \DNSSYS{} and \DHTSYS{}. We find that our approach is more
  effective than manual checksum verification or prior automated verification
  schemes at detecting resource integrity attacks. Further, we show that our
  \DNSSYS{} implementation is capable of detecting real-world integrity errors
  in a patched HotCRP instance, even when the entire server itself is
  compromised, significantly raising the bar for an attacker. Finally, we
  observed no download performance overhead compared to downloads without
  \DNSSYS{}.

\end{itemize}
