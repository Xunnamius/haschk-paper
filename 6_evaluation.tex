\section{Evaluation} \label{sec:evaluation}

In this section, we evaluate our implementation empirically using a patched
HotCRP instance and random sampling of papers published in previous
\CONFERENCE{} proceedings. We then examine the performance impact, deployment
overhead, and scalability of our implementation. We show that \SYSTEM{} is more
effective than existing approaches at detecting integrity problems in arbitrary
downloads over the internet.

\subsection{Security and Performance}

To empirically evaluate our implementation, we launch a lightly modified version
of the popular open source research submission and peer review software, HotCRP
(version 2.102; see \secref{sec:availability}). Our modifications allow anyone
visiting the site to interactively corrupt submissions and manipulate relevant
DNS entries at will.

For our evaluation, we upload 10 different \CONFERENCE{} PDFs to our HotCRP
instance. Upon their upload, HotCRP calculated and displayed the unique checksum
(a SHA-256 digest) of each PDF. After each PDF is uploaded, we immediately
download it and manually calculate a checksum locally, matching each to the
checksum displayed by the HotCRP software. Next, we utilize the custom
functionality we patched into HotCRP to populate our DNS backend with each
file's expected URN.

After installing the frontend into our Google Chrome browser, we again download
each file. For each observed download, our extension indicated a ``safe''
judgement. We then utilize our patched functionality to add junk data onto the
end of each of the uploaded PDFs, thus corrupting them. We also modified HotCRP
so that it updated the displayed checksums to match their now-corrupted
counterparts.

Once again, we download each file. Our extension reported an ``unsafe''
judgement (a true positive) for each corrupted PDF file. Calculating the local
checksum and checking it against the value reported by our HotCRP instance leads
to a match (a false negative; \ie{, the result of co-hosting}), defeating prior
approaches to both manual and automated checksum verification.

We ran this experiment three times, each with different sets of PDFs and using
both the DNS and DHT based backends. We observed consistent results.

Finally, we utilize our patched functionality to test a ``redirection'' attack
where the hyperlink pointing to the correct PDF is replaced with a hyperlink to
a dummy malware file hosted in a distinct malicious DNS zone with conforming
\SYSTEM{} deployment. When an unsuspecting user clicks such a link, they expect
to download the PDF document from HotCRP but are instead navigated to a PHP
script that redirects the request one or more times before landing on the dummy
malware file. This process corrupts Chrome's \texttt{DownloadItem.referrer}
property. Even in this case, our implementation correctly flagged this download
as suspicious once the download began, successfully warning the user.

While evaluating our implementation, we observe no additional network load or
CPU usage with the extension loaded into Chrome. Measurements were taken using
the Chrome developer tools. Intuitively, this makes sense given the lightweight
nature of the cryptographic operations involved.

We also consider the implications of a compromised backend, such as if an
attacker tampers with the provider's DNS server or its response. Since we trust
the integrity and authenticity of responses from the backend, this is ultimately
outside our threat model. However, in the case of a compromised DNS zone by
itself, at worst the attacker can perpetuate a denial of service attack by
triggering false positives. Without compromising both the backend and the
distribution server, the attacker still cannot deliver compromised resources to
users. Further, we argue a provider has much bigger problems if their DNS zone
or other backend is compromised.

\subsection{Deployment and Scalability}

\TODO{Argue why \SYSTEM{} is scalable and rewrite all of this mess.}

Clearly, the DNS backend relies on DNS. However, DNS~\cite{DNS1} was not
originally designed to transport or store relatively large amounts of data,
though this has been addressed with EDNS0~\cite{EDNS}. The checksums stored in
DNS should not be much longer than 128 bytes or the output of the SHA512
function. Regardless, DNS resource record extensions exist that store much more
than 128 bytes of data~\cite{CERT, IPSECKEY, DANE3, DANE1}.

Several working groups are considering DNS as a storage medium for
checksums/hash output as well, such as securitytxt~\cite{draft-sectxt}. A widely
deployed example of DNS ``TXT'' resource records being used this way is SPF and
DKIM~\cite{DKIM}. We are unaware of any practical limitation on the number of
resource records a DNS zone file can support~\cite{DNS1}, hence any
considerations regarding zone file size and/or ceilings on the number of TXT
records in a single zone are at the sole discretion of the implementing entity.

Additionally, the DNS-based backend does not add to the danger of amplification
and other reflection attacks on DNS; these are generic DNS issues addressable at
other layers of the protocol.

In respect to the DNS network, storing cryptographic data in DNS resource
records is not unprecedented. The DNS-Based Authentication of Named Entities
(DANE) specification~\cite{DANE1, DANE2, DANE3} defines the ``TLSA'' and
``OPENPGPKEY'' DNS resource records to store cryptographic data. These resource
record types, along with ``CERT''~\cite{CERT}, ``IPSECKEY''~\cite{IPSECKEY},
those defined by DNS Security Extensions (DNSSEC)~\cite{DNSSEC}, and others
demonstrate that storing useful cryptographic data retrievable through the DNS
network is feasible at scale. Due the unique requirements of DNS, however, we
use ``TXT'' records to map Resource Identifiers to Authoritative Checksums. In
accordance with RFC 5507~\cite{RFC5507}, a production implementation
implementation would necessitate the creation of a new DNS resource record type.

As \SYSTEM{} is predicated on a high availability backend and requires no
application/frontend source code changes to function, we conclude that the
scalability of \SYSTEM{} can be reduced to the scalability of its backend. We
are aware of no other obstacles to scalability beyond those inherited from the
underlying backend system.

In respect to DNS specifically, we are aware of no practical limits or
protocol-based restrictions on the scalability of a backend file itself or its
sub-zones. A service can host tens of thousands of resource records in their
backend file~\cite{DNS1, DNS2}.

With the HotCRP demo, the totality of our resource deployment scheme consisted
of the addition of a new TXT entry to our backend file---accomplished via API
call to Google DNS---during HotCRP's paper submission process. This new TXT
entry consisted of a mapping between a RI and its corresponding AC.

We find a DNS record addition or update during the resource deployment process
to be simple enough for service administrators to implement and presents no
significant burden to deployment outside of DNS API integration into a
development team or other entity's software deployment toolchain. For reference,
we implemented the functionality that automatically adds (and updates) the DNS
records mapping the ACs and RIs of papers uploaded to our HotCRP instance in
under 10 lines of JavaScript.

We note that, in the case where an entity's content distribution mechanism
relies on, for instance, a mirroring service, third-party CDN, et cetera
\emph{that randomly or disparately mangles resource URI paths}, our
implementations currently require each ``mangled'' RI permutation representing a
resource to be added to the backend, even if they all represent the same
resource by a different name/path.

\subsection{Limitations}

\TODO{Rewrite and finish me.}

Our current JavaScript implementations, as Chrome extensions, are not allowed to
touch the resource files downloaded by Chrome and so cannot prevent a
potentially-malicious resource from being executed by the user---a feature
Chrome/Chromium reserves for its own internal use. The Chrome \textit{app}
API~\cite{AppAPI} might have been of assistance as it allowed for some limited
filesystem traversal via a now deprecated native app API; there is also a
non-standard HTML5/WebExtensions FileSystem API that would provide similar
functionality were it to be widely considered~\cite{deadSpec}.

While still effective, our implementation would be even more effective as
browser extensions if Chrome/Chromium or the WebExtensions API allowed for an
explicit \texttt{onComplete} event hook in the downloads API. This hook would
fire immediately before a file download completed and the file became
executable, \ie{ had its \texttt{.crdownload} or \texttt{.download} extension
removed}. The hook would consume a \texttt{Promise}/\texttt{AsyncFunction} that
kept the download in its non-complete state until said \texttt{Promise}
completed. This would allow the extensions' background pages to do something
like alter a download's \texttt{DangerType} property and alert the user to a
dangerous download naturally. These modifications would have the advantage of
communicating intent through the browser's familiar UI and preventing the
potentially-malicious download from becoming immediately executable.
Unfortunately, the closest the Chrome/WebExtensions API comes to allowing
\texttt{DangerType} mutations is the \texttt{acceptDanger} method on the
downloads API, but it is not suitable for use with a background page based
extension.

While nice to have, we stress that none of the aforesaid functionality is
critical to the ability of our implementations to more effectively mitigate SCA
risk than checksums and other solutions (cf. \secref{evaluation}).

\TODO{Redirection, like with URI shortening services, might still break things
even with fallthrough functionality if a domain on the redirect chain has DNS
entries \SYSTEM{} recognizes}

\TODO{Does not work for PDFs and other downloads handled directly by the
browser}

\TODO{Given the topology of the webrequest API, iframes and the like may require
special consideration. May need to compare documenturi with origin uri.}

\TODO{Not all servers/backends on the internet use DNS. Direct IP not
supported.}

\TODO{Right now our PoC extension keeps 1000 requests in memory so that they can
be mapped to download items. This might be vulnerable to attacks involving
excessive redirection.}

\TODO{An ideal implementation is able to rely on Google Chrome's effective
dangerous download UI~\cite{ChromeClickThrough}. AcceptDanger does not work for
downloads that have already finished, however. Suggestion to the Chrome dev team
to implement something nicer.}
