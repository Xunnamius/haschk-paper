\section{The \SYSTEM{} Approach} \label{sec:approach}

In this section we detail the \SYSTEM{} approach: a novel defense against
receiving corrupted or compromised resources over the internet. We further
present the challenges and their solutions in designing \SYSTEM{} that
transparently mitigates resource integrity Supply Chain Attacks (SCA) without
degrading the experience of users that do not implement the \SYSTEM{} approach.

Further, though our concrete implementations relies on DNS authenticated with
DNS Security (DNSSEC), the approach itself is flexible and completely agnostic
of any single component. The implementation choice of highly-available
distributed \emph{backend}, for instance, is not restricted to the DNS network.
The approach works just as well with an authenticated Distributed Hash Table
(DHT) or some distributed authenticated key-value store (\eg Redis) as the
backend.

\TODO{Create the overview image or remove this sentence} \figref{overview}
illustrates the \SYSTEM{} approach.

\PUNT{Frontend:}
\subsection{Transparency and User Apathy}

Human factors such as user apathy have stymied cryptographers for decades.
Schemes that are otherwise reasonably cryptographically solid can fail
catastrophically due to human error, confusion, or simple lack of interest. Some
users are just as likely to avoid using a security measure altogether if it
presents even a minor obstacle to immediate gratification~\cite{Clickthrough,
PGPBad}. In the browser, for example, can observe this empirically.

Leveraging the in-browser telemetry of Mozilla Firefox and Google Chrome to
passively observe over 25 million warning impressions in 2013, Akhawe et al.
found that users of Google Chrome clicked through a quarter of \emph{malware and
phishing warnings} and \emph{70\% of TLS warnings}~\cite{Clickthrough}. Users
also clicked through a third of Mozilla Firefox's TLS warnings and a tenth of
their malware and phishing warnings. That is to say: a significant percentage of
browser users are \emph{determined} not to be let TLS trust issues and/or the
threat of malware prevent them from receiving their desired content. Hence, we
must assume: some non-trivial number of users, similarly \emph{determined} to
transact resources over the internet, will not be burdened with the off-path
minutiae of manually calculating a checksum (if they are even familiar with the
jargon) and verifying the integrity of the resources they're downloading.

With this assumption in mind, the primary goal of \SYSTEM{} then is to side-step
the human factor altogether by providing a completely transparent and
unobtrusive fully automated method of checksum calculation and verification. We
achieve this through 1) the unique identification of individual hosted resources
and 2) the globally available mapping of unique resource identifiers to
checksums.

A typical flow can be summarized as (now we introduce some jargon)

Maybe a figure too as well?

Reference the Chrome/FileZilla extensions as addressing user apathy but save the main conversation for later.

\PUNT{Backend:}
\subsection{Defeating Co-Hosting, Sometimes for Free}

Cohosting is bad. Reiterate why (from intro).

Though the concept of using some distributed authenticated storage mechanism to
query a global mapping between RIs and AHs sounds intuitive and straightforward,
two natural concerns arise.

The first: modern durable authentication schemes are based on PKI; who is
managing the keypairs?

The second: who is paying to maintain this secondary system? Who is bearing the
burden of its maintenance?

\subsection{Platform Diversity}

Not computationally intensive. Requests are small, low network load. See eval.

Hence, the approach can be incorporated into software on any device capable of
communicating with a distributed authenticated backend. This includes desktops,
laptops, tablets, mobile devices, embedded systems.

\subsection{Proof-of-Concept Implementations}

\TODO{Talk about the Chrome/FileZilla extensions as addressing user apathy}

A Resource Identifier (RI) is the unique cryptographic digest yielded by hashing
the full file path of the resource, including leading slash if applicable. For
example, considering a web resource hosted at
\textit{https://somesite.com/downloadme.txt}, a browser-based \SYSTEM{}
implementation would hash \textit{/downloadme.txt} to get the RI.

The Authoritative Hash (AH) is yielded from a record request to the backend.

The Non-Authoritative Hash (NAH) is calculated by hashing the contents of the
resource after it has been received in its entirety.

Non-Authoritative Hash Validation (NAH Validation) is the final stage before
\SYSTEM{} renders judgement on the downloaded resource's integrity. The NAH is
compared to the AH received from backend. If they do not match, the file is
judged unsafe.

The Origin Domain (OD) is used to determine how \SYSTEM{} communicates with the
backend. In a browser-based implementation, the OD is the Second-Level Domain
(SLD) fragment of the current tab's URL. For example:
\emph{google.com} would be the OD for the URL \emph{frag.something.google.com}
and \emph{fakesite.io} would be the OD for the URL \emph{git.fakesite.io}.

\subsubsection{Google Chrome}

\TODO{(Google Chrome Extension: describe implementation details; works with DNS
or DHT and is published to Chrome store; no interface changes!--i.e. downloads
work exactly the same with or without the extension; users still have to
confirm/deny suspicious judgements, but they are rare occurrences)}

The Primary Label (PL) is a standard string used to identify DNS records that
belong to \SYSTEM{}. It will always appear as the third-level domain following the
OD.

The RI Sub-Label (SL) is a standard string used to identify DNS records that
contain RIs.

Chrome: the origin domain is determined via DownloadItem::referrer. This is to
make it harder for an adversary to trick \SYSTEM{} into calculating an incorrect
OD.

\TODO{Reference hotcrp demo but leave the description for the evaluation.}

\begin{algorithm}[t]
    %\floatname{algorithm}{Algorithm}
    \caption{Handling an incoming download in Chrome} \label{algo:dnschk}
    {\footnotesize
    \begin{algorithmic}[1]
    \Require The read request is over a contiguous segment of the backing
    store
    \Require $\ell, \ell' \leftarrow$ read requested length
    \Require $\aleph \leftarrow$ master secret
    \Require $n_{index} \leftarrow$ first nugget index to be read
    \State $data \leftarrow$ \emph{empty}
    \While{$\ell \neq 0$}
        \State $k_{n_{index}} \leftarrow GenKey_{nugget}(n_{index}, \aleph)$
        \State Fetch nugget keycount $n_{kc}$ from Keycount Store.
        \State Calculate indices touched by request: $f_{first}$, $f_{last}$
        \State $n_{flakedat} \leftarrow ReadFlakes(f_{first},\dots,f_{last})$
        \For{$f_{current} = f_{first}$ \textbf{to} $f_{last}$}
            \State $k_{f_{current}} \leftarrow GenKey_{flake}(k_{n_{index}},
            f_{current}, n_{kc})$
            \State $tag_{f_{current}} \leftarrow GenMac(k_{f_{current}},
            n_{flakedat}[f_{current}])$
            \State Verify $tag_{f_{current}}$ in Merkle Tree.
        \EndFor
        \LineComment{(\textbf{*}) denotes requested subset of nugget data}
        \State $data \leftarrow data + Decrypt(*n_{flakedat}, k_{n_{index}},
        n_{kc})$
        \State $\ell \leftarrow \ell - \|*n_{flakedat}\|$
        \State $n_{index} \leftarrow n_{index} + 1$
    \EndWhile
    \\\Return $data$ \Comment{Fulfill the read request}
    \Ensure $\|data\| <= \ell'$
    \Ensure $\ell = 0$
    \vskip -1.5em
    \end{algorithmic}
    }
\end{algorithm}

\subsubsection{Filezilla}

\TODO{(FileZilla (FTP) Patch (only talked about here) describe implementation
details; minor interface change if the download is judged unsafe or suspicious,
requires user to confirm/deny download)}
